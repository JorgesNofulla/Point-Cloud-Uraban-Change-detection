{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc5c69-7c75-4f12-abc9-c824f6dd8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import laspy as lp\n",
    "import matplotlib\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KDTree\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f4a9e-394c-412d-a504-4fdf2fe4a395",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64bd6f-4f72-4220-bd18-04e8faacc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('CNN_FULL_Training_features.npy')\n",
    "y_train = np.load('CNN_FULL_targets_train.npy')\n",
    "X_val = np.load('CNN_Validation_features.npy')\n",
    "y_val = np.load('CNN_Validation_targets.npy')\n",
    "X_test = np.load('CNN_test_1tile_features.npy')\n",
    "y_test = np.load('CNN_test_1tile_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c719f-556e-4e6d-b4f3-caac192d5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, :-1]\n",
    "X_test = X_test[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf7087-deb5-4334-aea8-97e8f0909b3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Find the neighbours for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9c62c-f838-4155-a5c3-2e39714157ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of nearest neighbors to consider\n",
    "k_neighbors = 10\n",
    "\n",
    "# Calculate the nearest neighbors for each data point using KD-Tree\n",
    "tree = KDTree(X_train)\n",
    "tree2 = KDTree(X_test)\n",
    "nearest_neighbors_train = tree.query(X_train, k=k_neighbors+1, return_distance=False)[:, 1:]\n",
    "nearest_neighbors_test = tree2.query(X_test, k=k_neighbors+1, return_distance=False)[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b05268-2a83-4cf3-8712-f622b2ac9cab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Prepare the data format for the CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d77cba-7984-43e1-b12c-cc51082920c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the input data for training the model\n",
    "def generate_input_array(X, nearest_neighbors):\n",
    "    input_array = np.concatenate([X[:,3:][nearest_neighbors[:, i]] for i in range(k_neighbors)], axis=1)\n",
    "    return input_array.reshape(-1, k_neighbors, X[:,3:].shape[1], 1)\n",
    "\n",
    "input_array_train = generate_input_array(X_train, nearest_neighbors_train)\n",
    "input_array_test = generate_input_array(X_test, nearest_neighbors_test)\n",
    "\n",
    "# Normalize the nearest_neighbors arrays\n",
    "scaler = StandardScaler()\n",
    "input_array_train = scaler.fit_transform(input_array_train.reshape(input_array_train.shape[0], -1))\n",
    "input_array_test = scaler.fit_transform(input_array_test.reshape(input_array_test.shape[0], -1))\n",
    "input_array_train = input_array_train.reshape(-1, k_neighbors, X_train[:,3:].shape[1], 1)\n",
    "input_array_test = input_array_test.reshape(-1, k_neighbors, X_test[:,3:].shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6071cb92-62d1-4ec9-a4e8-139f953fc79d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Desing the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d749a2f-5d0b-41fe-bc76-c7909ddbe859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu', padding='same', input_shape=(k_neighbors, 8)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=2, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, kernel_size=2, activation='relu', padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=2, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(32, kernel_size=2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b2c88-9a2a-41a2-988d-dff895fc9294",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723dd12-bc19-4089-9de2-c02e929f9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_array_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "loss, accuracy = model.evaluate(input_array_test, y_test)\n",
    "\n",
    "# Print the accuracy as a percentage\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6141e6-2eab-4044-8c83-01360667e81d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543abb01-c506-4009-ad1c-35a5a4da1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_modified = np.argmax(model.predict(input_array_test), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2ab6a-6c4c-4672-a31c-a82e399e5a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Per class accuraccies, reports and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378d34b-9a2a-4403-bbde-1637468c2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_modified = confusion_matrix(y_test, y_pred_modified)\n",
    "class_accuracies_modified = cm_modified.diagonal() / cm_modified.sum(axis=1)\n",
    "for i, acc in enumerate(class_accuracies_modified):\n",
    "    print(f\"Accuracy for class {i} (Modified architecture): {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cde654-85e1-4631-a1de-f2360e3a0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('second_HALF_CNN_10epoch_10neigh_64batch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55669f-7e68-4206-8fb6-d98f420b6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['unchanged', 'new_building', 'demolition', 'new_vegetation', 'vegetation_growth', 'vegetation_loss', 'mobile_objects']\n",
    "print(classification_report(y_test, y_pred_modified, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161ddc3-e5f4-4bb7-b553-c03930d1629a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the report in a csv format\n",
    "report = classification_report(y_test, y_pred_modified, target_names=target_names, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('BESTclassification_report_cnn-secondhalf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61fe70-f41b-4acb-9605-69b9a6f90053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix plot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_modified)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('BESTconfusion_matrix-half.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08de77-3eaa-47e7-aad4-1f83cd6c4a01",
   "metadata": {},
   "source": [
    "# Cluster cleaning the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28a8c1-a468-475f-a5e2-7d19d3df9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = y_pred_modified\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "\n",
    "for label in np.unique(targets):\n",
    "    current_points = X_test[:,0:3][targets == label]\n",
    "    clustering = DBSCAN(eps=2.5, min_samples=1).fit(current_points)\n",
    "    current_unique_labels = np.unique(clustering.labels_)\n",
    "    small_cluster_points = np.zeros(current_points.shape[0], dtype=bool)\n",
    "    \n",
    "    for current_label in current_unique_labels:\n",
    "        if current_label == -1:\n",
    "            continue\n",
    "        current_cluster = clustering.labels_ == current_label\n",
    "        if current_cluster.sum() < 20:\n",
    "            small_cluster_points[current_cluster] = True\n",
    "\n",
    "    current_labels = targets[targets == label].copy()\n",
    "    current_labels[small_cluster_points] = 0\n",
    "    targets[targets == label] = current_labels\n",
    "\n",
    "# Go through all zero clusters and change small ones to closest non-zero label\n",
    "zero_indices = np.where(targets == 0)[0]  # Indices of zero targets\n",
    "zero_points = X_test[:,0:2][zero_indices]  # Use only first two dimensions\n",
    "clustering = DBSCAN(eps=1.5, min_samples=1).fit(zero_points)\n",
    "unique_labels = np.unique(clustering.labels_)\n",
    "small_cluster_points = np.zeros(zero_points.shape[0], dtype=bool)\n",
    "\n",
    "for current_label in unique_labels:\n",
    "    if current_label == -1:\n",
    "        continue\n",
    "    current_cluster = clustering.labels_ == current_label\n",
    "    if current_cluster.sum() < 10:\n",
    "        small_cluster_points[current_cluster] = True\n",
    "\n",
    "small_zero_indices = zero_indices[small_cluster_points]  # Indices of small zero clusters\n",
    "non_zero_targets = targets[targets != 0]\n",
    "non_zero_points = X_test[:,0:2][targets != 0]  # Use only first two dimensions\n",
    "\n",
    "# Create a BallTree for efficient nearest neighbor search\n",
    "tree = BallTree(non_zero_points)\n",
    "\n",
    "# Query the BallTree for nearest neighbors\n",
    "distances, indices = tree.query(zero_points[small_cluster_points], k=1)\n",
    "\n",
    "# Replace zero labels with nearest non-zero labels\n",
    "targets[small_zero_indices] = non_zero_targets[indices.flatten()]\n",
    "\n",
    "# Print the updated labels\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfb6ca-ae80-4ffe-a142-24266508f41f",
   "metadata": {},
   "source": [
    "# Save output as las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9d126-b116-4c10-b43e-851f74c1fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_coord = X_test[:, :3]\n",
    "fn = \"output_file.las\"\n",
    "\n",
    "vals = np.linspace(0, 1, 100)\n",
    "np.random.shuffle(vals)\n",
    "cmap = plt.cm.colors.ListedColormap(plt.cm.tab20(vals))\n",
    "header = lp.header.Header()\n",
    "header.data_format_id = 2\n",
    "fp = lp.file.File(fn, mode = 'w', header = header)\n",
    "fp.header.scale = [0.01, 0.01, 0.01]\n",
    "fp.header.offset = [min(print_coord[:,0]), min(print_coord[:,1]), min(print_coord[:,2])]\n",
    "fp.x = print_coord[:, 0]\n",
    "fp.y = print_coord[:, 1]\n",
    "fp.z = print_coord[:, 2]\n",
    "fp.pt_src_id = targets\n",
    "#fp.intensity = intensity\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
