{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33159c1f-68d2-4cb3-b38f-7ed030aa5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib.cm import tab20 as cmap\n",
    "from matplotlib import pyplot as plt\n",
    "import laspy as lp\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72f375-1b27-4eb6-9e1c-d2947fb26238",
   "metadata": {},
   "source": [
    "# Load the train and test data for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e55783f-8d72-404b-9e3f-5ae289b29886",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('test_data_ahn.npy')\n",
    "y_train = np.load('targets_ahn_test.npy')\n",
    "X_test = np.load('test_data_ahn.npy')\n",
    "y_test = np.load('targets_ahn_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c0d9fea-3a05-4fda-ade8-64735ca8346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = x_new_test2[:,3:]\n",
    "test_coordinates = X_test[:,:3]\n",
    "X_train = X_train[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6fc5741-1c46-4243-9c12-82475139b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform the data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.fit_transform(X_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d6a33-0da8-4204-9de0-d1b095bf5a6c",
   "metadata": {},
   "source": [
    "# First version of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e31d72-42ed-4277-8d99-be4e46f5048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your Neural Network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=8))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7, activation='softmax')) # 7 is the number of classes in your target variable\n",
    "\n",
    "# Compile your Neural Network\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train your Neural Network on the same validation set\n",
    "history = model.fit(X_train_scaled, y_train, epochs=8, batch_size=32)\n",
    "\n",
    "# Evaluate your Neural Network on the testing set\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Print the accuracy as a percentage\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899de6f-39ef-415f-9263-54acf9d491ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict data\n",
    "# Use your trained Neural Network to predict probabilities on new data\n",
    "nn_probs = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "nn_labels = np.argmax(nn_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ec6ec-cf23-4e87-b73a-9208ae29cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_modified = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "cm_modified = confusion_matrix(y_test, y_pred_modified)\n",
    "\n",
    "class_accuracies_modified = cm_modified.diagonal() / cm_modified.sum(axis=1)\n",
    "for i, acc in enumerate(class_accuracies_modified):\n",
    "    print(f\"Accuracy for class {i} (Modified architecture): {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2531b-f8de-43b7-a320-a0d72caccd91",
   "metadata": {},
   "source": [
    "# Another version of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d60a2-1e59-44e9-b7dd-fd4afff177f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU, PReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define your Neural Network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=8))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(PReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile your Neural Network\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Set up a learning rate scheduler\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Train your Neural Network on the same validation set\n",
    "history = model.fit(X_train_scaled, y_train, epochs=8, batch_size=64) #validation_split=0.2, callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate your Neural Network on the testing set\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Print the accuracy as a percentage\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401b0bc-0292-45f9-9835-7d4dd0d3f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your Neural Network on the testing set\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Print the accuracy as a percentage\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e8fd5-e877-4c64-a796-45436b3f3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_modified = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "cm_modified = confusion_matrix(y_test, y_pred_modified)\n",
    "\n",
    "class_accuracies_modified = cm_modified.diagonal() / cm_modified.sum(axis=1)\n",
    "for i, acc in enumerate(class_accuracies_modified):\n",
    "    print(f\"Accuracy for class {i} (Modified architecture): {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec277f99-188b-469a-81f6-c9c2df6cec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your trained Neural Network to predict probabilities on new data\n",
    "nn_probs = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "nn_labels = np.argmax(nn_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22238647-6ee1-4200-9dac-be7673a124c7",
   "metadata": {},
   "source": [
    "# Save the predicted area as an las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83783fb-0a2a-4c53-890e-8cd638aa7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_coord = x_new_test2[:, :3]\n",
    "fn = \"Final_of_day_pred_preds.las\"\n",
    "\n",
    "vals = np.linspace(0, 1, 100)\n",
    "np.random.shuffle(vals)\n",
    "cmap = plt.cm.colors.ListedColormap(plt.cm.tab20(vals))\n",
    "header = lp.header.Header()\n",
    "header.data_format_id = 2\n",
    "fp = lp.file.File(fn, mode = 'w', header = header)\n",
    "fp.header.scale = [0.01, 0.01, 0.01]\n",
    "fp.header.offset = [min(print_coord[:,0]), min(print_coord[:,1]), min(print_coord[:,2])]\n",
    "fp.x = print_coord[:, 0]\n",
    "fp.y = print_coord[:, 1]\n",
    "fp.z = print_coord[:, 2]\n",
    "fp.pt_src_id = nn_labels\n",
    "#fp.intensity = intensity\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
