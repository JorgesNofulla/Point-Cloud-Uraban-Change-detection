{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193d9747-cba5-4f2b-927f-17eeee363942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import laspy as lp\n",
    "import pylas\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b01d09-c70a-44d6-8eca-9ea92ff1a4af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OPTIONAL! / Check the labels and what are they called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5db5b2f-4b36-43c5-a838-04cd332ba474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This las file has 1660906 points\n",
      "('X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'synthetic', 'key_point', 'withheld', 'scan_angle_rank', 'user_data', 'point_source_id', 'red', 'green', 'blue')\n",
      "This las file has 3 unique classifications\n"
     ]
    }
   ],
   "source": [
    "las_test = pylas.open('AHN.las')\n",
    "data = las_test.read()\n",
    "array_test = data.point_source_id\n",
    "print(\"This las file has\", len(data.points), \"points\")\n",
    "data2 = data.point_format\n",
    "print(data2.dimension_names)\n",
    "counter_object3 = Counter(array_test)\n",
    "keys3 = counter_object3.keys()\n",
    "num_values3 = len(keys3)\n",
    "print(\"This las file has\", num_values3, \"unique classifications\")\n",
    "# building = 6\n",
    "# ground = 2\n",
    "# others = 1\n",
    "# water = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220872c9-b281-449f-a105-f6fd93457d04",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. LOAD the data and Lower the point density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad46e92-7319-4814-8acd-bb5b73ea20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially we had 10194918 17668119 points. But, after lowering the point denity, the number of remainig points is 1218875 1245790\n"
     ]
    }
   ],
   "source": [
    "f = lp.file.File('AHN3.las', mode=\"r\")\n",
    "f2 = lp.file.File('AHN4.las', mode=\"r\")\n",
    "\n",
    "# concatenate the file coordinates\n",
    "coord = np.c_[f.x, f.y, f.z, f.red, f.green, f.blue, f.intensity, f.classification]\n",
    "coord2 = np.c_[f2.x, f2.y, f2.z, f2.red, f2.green, f2.blue, f2.intensity, f2.classification]\n",
    "\n",
    "# bring the points into a local coordinate system\n",
    "# now we have smaller coordiante values to deal with\n",
    "\n",
    "xi = (f.x).astype('int')\n",
    "yi = (f.y).astype('int')\n",
    "zi = (f.z).astype('int')\n",
    "xi2 = (f2.x).astype('int')\n",
    "yi2 = (f2.y).astype('int')\n",
    "zi2 = (f2.z).astype('int')\n",
    "\n",
    "# Reduce the data! get a flat voxel index ii\n",
    "# lowers the number of points feed to the algorithm\n",
    "ii = xi + yi * xi.max() + zi * yi.max() * xi.max()\n",
    "_, sl = np.unique(ii, return_index=True)\n",
    "coord = coord[sl, :]\n",
    "\n",
    "#\n",
    "ii2 = xi2 + yi2 * xi2.max() + zi2 * yi2.max() * xi2.max()\n",
    "_, sl2 = np.unique(ii2, return_index=True)\n",
    "coord2 = coord2[sl2, :]\n",
    "print(\"Initially we had\", len(f.x), len(f2.x), \"points. But, after lowering the point denity, the number of remainig points is\", len(coord), len(coord2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0899188-6c21-4dea-a2b4-5913caa6e054",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Match the data from 2 different epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2560652-a597-4dde-a6c0-36ad025a5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct KDTree from array2\n",
    "tree = KDTree(coord2[:, :2])\n",
    "\n",
    "# Find the closest point in array2 to each point in array1\n",
    "dist, ind = tree.query(coord[:, :2])\n",
    "\n",
    "# Reorder array2 based on ind\n",
    "array2_reordered = coord2[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74569bc8-d0fd-44a5-9a5a-b02e4ff7f611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218875\n",
      "1218875\n"
     ]
    }
   ],
   "source": [
    "print(len(array2_reordered))\n",
    "print(len(coord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4422c8-1a29-483f-bdd8-1970e09834d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(coord, columns=['xAHN3', 'yAHN3', 'zAHN3', 'redAHN3', 'greenAHN3', 'blueAHN3', 'intensityAHN3', 'labelAHN3'])\n",
    "df2 = pd.DataFrame(array2_reordered, columns=['x', 'y', 'z', 'red', 'green', 'blue', 'intensity', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5c96db-a36d-4865-a6d4-bafc6b03fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(\n",
    "    np.column_stack([df1,df2]),\n",
    "    columns=df1.columns.append(df2.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e1ae90-b28e-4850-a2d2-b88517c37216",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf_2 = df3\n",
    "# new_gdf_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae0890-7b98-4cb7-b6bf-7389e91868ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Generate the change_label target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5bc7c02-5724-4c37-8e25-8683736ca348",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf_2[\"change_label\"] = new_gdf_2.apply(lambda x: 1 if x[\"labelAHN3\"] == 6 and x[\"label\"] !=6 else 2 if x[\"label\"] == 6 and x[\"labelAHN3\"] != 6 else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf4c6be-3f3f-4346-9132-a8eddaf3d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_gdf_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4d0f0-5c85-408a-8bd7-8a3fb016cb2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Prepare and save the arrays for deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b848429-053b-421d-b9b8-527f4b7b13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data in an array format\n",
    "data_array = new_gdf_2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e78c156-cb7f-4d9a-af35-1499ffe47f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and targets\n",
    "\n",
    "ahn3_features = data_array[:, 2:7]  # z until intensity\n",
    "ahn4_features = data_array[:, 10:15]  # z of second data until intensity of second data\n",
    "targets = data_array[:, 16]  # change label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c1c286-076a-4825-b6af-4485cd783a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Subtract and add features from 2 epochs with each other to get a single input\n",
    "result_substraction = ahn3_features - ahn4_features\n",
    "result_addition = ahn3_features + ahn4_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386a1ec0-8014-4b1c-ae71-dab04e7ee9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the coordinates alongside the new merged features\n",
    "ahn_train_data = np.c_[data_array[:, 0:3], result_addition, result_substraction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc18b14-049a-41d0-9e5d-406306b6f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to stack multiple training data into one to train algorithm with more than just one tile\n",
    "# AHN_train_stack = np.vstack((train_data,train_data2))\n",
    "# AHN_target_stack = np.vstack((targets,targets2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "117bee8f-9d68-4116-8073-7dbe7f6b42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the arrays\n",
    "\n",
    "np.save('ahn_train_data.npy', ahn_train_data)\n",
    "np.save('targets.npy', targets)\n",
    "# np.save('AHN_train_stack.npy', AHN_train_stack)\n",
    "# np.save('AHN_target_stack.npy', AHN_target_stack)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
